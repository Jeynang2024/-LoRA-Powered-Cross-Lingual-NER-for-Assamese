{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbKH1PVXq936"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook explores a practical and modern approach to low-resource *Named Entity Recognition (NER)* for the **Assamese** language by leveraging cross-lingual transfer learning and Parameter-Efficient Fine-Tuning (PEFT) techniques"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dK7KEjwrOcw"
      },
      "source": [
        "The core idea is:\n",
        "\n",
        "Use *Hindi* + *Bengali*  NER datasets to improve the representation quality of Assamese tokens, and then fine-tune the model on Assamese using lightweight **LoRA** adapters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Sf8SoccrjIT"
      },
      "source": [
        "## Motivation\n",
        "\n",
        "Assamese is a low-resource Indic language with extremely limited annotated NER datasets.\n",
        "Training deep transformer models (e.g., XLM-R) directly on such small datasets leads to:\n",
        "\n",
        "- unstable training\n",
        "\n",
        "- low accuracy\n",
        "\n",
        "- poor generalization\n",
        "\n",
        "However, linguistically and script-wise, Assamese is closely related to Bengali and partially similar to Hindi.\n",
        "We leverage this relationship through:\n",
        "\n",
        "- Cross-lingual pre-adaptation using Hindi + Bengali NER\n",
        "\n",
        "- LoRA-based fine-tuning to avoid full-parameter updates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grPvv4KJrzRb"
      },
      "source": [
        "## Parameter-Efficient Fine-Tuning (PEFT)\n",
        "\n",
        "Modern transformer models contain hundreds of millions of parameters.\n",
        "Fine-tuning all of them for each new task is:\n",
        "\n",
        "- slow\n",
        "\n",
        "- expensive\n",
        "\n",
        "- overfits on small datasets\n",
        "\n",
        "- impractical for low-resource languages\n",
        "\n",
        "PEFT solves this by training only a very small subset of parameters, while keeping the base model frozen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDtwrw6qKTZk",
        "outputId": "76d1dd0c-531a-4503-fce8-32d6832f3d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers datasets seqeval peft accelerate  evaluate\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "g1hxTh9TN6QO"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report, f1_score\n",
        "from datasets import load_dataset,DatasetDict, concatenate_datasets\n",
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForTokenClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorForTokenClassification,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272,
          "referenced_widgets": [
            "08a13ff6dd5e4f0782f5c957e21c3af9",
            "087293e6edf04b968def1ae34f0c008d",
            "19e833a7567b4306ab55b71b816483fe",
            "ba40c4b9dc4a40c89ad032a652dc43a9",
            "d677acb47a494abfac4d1454d604296e",
            "94345a030046485b944d1549c5b85756",
            "2b8b08ba4b084d07b5006cbd0bcbf2d7",
            "3b69403822d24b42b5d8749eba49fed7",
            "643067492bbf4f0ca42d480f33539ab4",
            "f05248e91aa34acf85051cfb7a161f8b",
            "cb66bb621c584a819c2b7d523ab4d66c",
            "f960e112c0134cafbabf3ca3728f6379",
            "7ce191bc33784fe9a619fa6fb594e997",
            "cd3871b692784e2793da6d300489e319",
            "1f5cbe8c6a8643c79500a613e7fd1d94",
            "9924aace867a4939b540f20271a16adc",
            "03390e2f4d5b4e5ebedd1e6a27b887cc",
            "bafa82b44d4243e295fad5728bbf25d7",
            "2257064c456f43a1970a77f5b5a977e9",
            "a9a2469f20dc435886570cc1f6a05b54",
            "5915f928f0c94f069019fade9731b682",
            "e99db01cbfcc4931bc48423bcb898c27",
            "0ac1ccdfced548f4a2bbd30ed7b67008",
            "614cc6c2acd24830ac6129c17e207f4f",
            "75bd112116a94dddb384a56c9c788bf9",
            "1807420d3c294eb38b69dc4c10738f3a",
            "6eb1abec7e54456797ddaee0c8e92a5b",
            "0cd5580870cc4c679130d4c53868c5f8",
            "23a31cac944d4bbb9fea7ead2a6be0c1",
            "d3a7afa9f7884108a1226447faf0de1e",
            "19a6ad6a2f864a7a9cf2b8d806189c0c",
            "57b505d3ee9a416fbffcf1e5232254c4",
            "10d8c34fa39745448c71df093660e7f2",
            "b64de7226d0a4659a26e2cb7cd756b9e",
            "ce87eab01a6d456da5db257715d226f3",
            "111c5d3297484676b437e3fdddf3db46",
            "26d71c7cfb2f4582a5fe69af70ee23e3",
            "856e3bf37e804fa99ce9d8326ff3330f",
            "724a19c71f584e1188bf5fc83dd78d6b",
            "921466f4f64b4ceb826e3f14ccfb2d76",
            "ca967709866843309dc997020d14d450",
            "9f94f9ab545e40c89f7a8d2c8803de00",
            "004c9af0e5dc4c848165da1854ef4118",
            "4f87737c54974d9ab1a877327332b666"
          ]
        },
        "id": "9xGDDyf_Km7m",
        "outputId": "cfbf5339-1302-45cf-c8ef-763c02852aea"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08a13ff6dd5e4f0782f5c957e21c3af9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f960e112c0134cafbabf3ca3728f6379",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0ac1ccdfced548f4a2bbd30ed7b67008",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b64de7226d0a4659a26e2cb7cd756b9e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XH6oncaym1M"
      },
      "source": [
        "### Baseline Model Overview\n",
        "\n",
        "Before introducing *LoRA* adapters or cross-lingual alignment, we first establish a baseline using a straightforward fine-tuning of *XLM-RoBERTa Base* directly on the Assamese NER dataset.\n",
        "\n",
        "This baseline helps us measure:\n",
        "\n",
        "- how well XLM-R performs without any adaptation,\n",
        "\n",
        "- how much benefit we gain later from Hindi + Bengali transfer learning,\n",
        "\n",
        "- whether the Assamese dataset alone is sufficient to fine-tune a multilingual model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "ecaa7bbd8b5246328f69817ba8a24941",
            "56d63d55edd64c3882a2df91893f15c9",
            "0fc9414ae6e3404488a85fdfbb08ecb3",
            "b2411e8266de47f782a709b0ad5c9c1b",
            "a6ad9b5ee43545f9b80442d810e645fc",
            "8b2b6217a0754f72b1321ce9ab0c1e02",
            "2e417270d4a045778ebe8674fbae052d",
            "5ab9a6c04a4843f694fabce957a46e68",
            "4ae27bf21dd44025bde5185e6aa791e0",
            "9347bc63ed404156b47c77a42261841b",
            "7e6eb3ab631b4137887e017181adc237",
            "504d3ce7f98b46c394500a41f06b8811",
            "b068546c1a1744e2a888c302f4ebc9de",
            "450082dd6f7b4b23a9c9acbfb06f049b",
            "1ee8b5bca05f45e5a1e713da2816737e",
            "4f0d6de91a654879b7ea3faac5ce553a",
            "2d1f2e2772e74c2baf8249a939ebfeff",
            "9e120b77ac95443082add854ff16029d",
            "88fe2d3dd5e7450b97a7bdb6d3d3aa46",
            "95fa75e5fcb341a899c81106cde741da",
            "a591a65976674c43a268eb5bcf75c7df",
            "abea9deb59a249da87282d752ec9611a",
            "9ba6b711a2f34fb19b40086fd77e0feb",
            "2e161125bdd24c36ac13a85d6ca573a5",
            "aadb97b0a1a344c595144b9f88aae6d7",
            "855c7fdfe2674e5ca70785568122cd9e",
            "20d2c1f3e35847b897c3b8f436feb8f2",
            "24f82a727e7145a68816995cd15d9d73",
            "fbed592bc47249759f5ac62455aed512",
            "23aad4e8cdd2445da718da6751d8e51f",
            "4a66051bfcf34f83984ef4ab1cc581cf",
            "22e832904add4effb6f0eb1fc51ca155",
            "51d6cd9429c0448caafe8a23891d512b",
            "b0b90b617c0d4b6fafb533bc11168dc8",
            "51159b9b3a214513b1c22c50bb1ce867",
            "1d211313ee6544478757d742723e4174",
            "18e3c554c6004bdeac4f81aa6f656e75",
            "c52081034f7547cc97f51bd9f1a81354",
            "f000582d2a1049c79f4dde5332733d62",
            "cf8e433c9b8643499e32112a373ac322",
            "b476e9ea554e4962a89240da746181cc",
            "31ffb3075ee8456dbd93ee90aa86f319",
            "430bc1eabf2741f1a4306233e764d437",
            "c98834947e244181aaf8fc9bcee4e51f",
            "07966507f75a418b966a4c8d35d75b13",
            "65dbb883b89849a2af8bfbdd77294328",
            "d740c83f087c486b892b572ab16499f7",
            "2a336229471e407a99baa9a0c2805675",
            "243730d1581a401ea138bbe17e1ab831",
            "c86fc24dc27e4ee8a46c4dde5d568cad",
            "ad0a320d8e9d4d928da1714f4c4bc309",
            "2fb163162e0741d082c97d851d6f8a1e",
            "43827e4e105b47e49609c97c9f76d92c",
            "e97eaf9a883c4091a465d326e7923719",
            "eeb8f0e9c69a431bb144b47fff2db9c3",
            "06f1f687809c44a48bf19484450d0707",
            "03017f6337c64c2ea5a8f621800e5b8a",
            "5cb7050273e446da9cfea66dea0aec21",
            "65b4ac4e65a44a6eaa24f59b4d55ff10",
            "b864c283130b426b9506f2591b01fcbd",
            "4eee35fc09b74d90965b62bbcbe27d13",
            "9adf0276436d4336971fb27d87567936",
            "7f6fb921a4164405a899218c800165db",
            "8a87263390d54c29845ec7948edd45d1",
            "8a667d9aa9254eb880cb8ae64f283c29",
            "8479f1d0d82b4f2cb7db9ddc7d41c1f8",
            "11299be55bd049279d5706ef4ee33325",
            "280267ec8c9944cebf52dd085862304a",
            "1f95ff5c9cb446f3a2a6984e6687ad59",
            "c68c06e235484ea29b9d9486f9e6aea1",
            "8813f9ba0fcd40fa9354f4b13ea27ac4",
            "ee596048522842e8a37478befd8149d3",
            "8ea055681c954fa587addd6cc932354d",
            "a01a35ab23e44263a2eca4c8f3ae65c4",
            "fa1ff2a16b1942be89ae9c27d827b674",
            "30ee00bfd84449e9a14bb42f39bfe218",
            "4590581a5ffc435ead9497f1285c203f"
          ]
        },
        "id": "OzjnLwRtGuWj",
        "outputId": "59cad832-6664-4e4f-eefc-4a53d321602b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecaa7bbd8b5246328f69817ba8a24941",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "504d3ce7f98b46c394500a41f06b8811",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "as/validation-00000-of-00001.parquet:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ba6b711a2f34fb19b40086fd77e0feb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "as/test-00000-of-00001.parquet:   0%|          | 0.00/9.68k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b0b90b617c0d4b6fafb533bc11168dc8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "as/train-00000-of-00001.parquet:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07966507f75a418b966a4c8d35d75b13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06f1f687809c44a48bf19484450d0707",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "11299be55bd049279d5706ef4ee33325",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "as_ds = load_dataset(\"wikiann\", \"as\")\n",
        "\n",
        "label_list = as_ds[\"train\"].features[\"ner_tags\"].feature.names\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qRnj2P-LKsjN"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "id2label = {i: l for i, l in enumerate(label_list)}\n",
        "label2id = {l: i for i, l in enumerate(label_list)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5ydQ4jHyq3D"
      },
      "source": [
        "### Tokenization :\n",
        "Tokenization is a fundamental step in NER pipelines because:\n",
        "\n",
        "- Transformer models use subword-level representations\n",
        "\n",
        "- NER labels are word-level\n",
        "\n",
        "- Proper mapping ensures meaningful training signals\n",
        "\n",
        "Correct tokenization alignment is a critical foundation before applying:\n",
        "\n",
        "- LoRA\n",
        "\n",
        "- cross-lingual training\n",
        "\n",
        "- Assamese-specific fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ThLCKdiAJdIo"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "    all_labels = []\n",
        "\n",
        "    for i in range(len(examples[\"tokens\"])):\n",
        "\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        example_labels = examples[\"ner_tags\"][i]\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(example_labels[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        all_labels.append(label_ids)\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = all_labels\n",
        "    return tokenized_inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "08626170f0ca427cb2e55fe7de69aacc",
            "16f3d9bac48d43d38c7440c098a7f023",
            "83060cc2ea054afe9a2d1a68d3b71d14",
            "283d9a35e7f04389b55484b1be7911e2",
            "11ff58e2112f4fb59d0d0d276f6efba9",
            "bd042b3785134ff1847c4630049ab71b",
            "b534f85285f84820b391d60932d57c50",
            "f431fdcdef5a40d1ad716c15ec1a19f3",
            "edb6a97d5a5341e6b3c2777b0ed0de35",
            "128c4fee41a542c0ab499e27851ff678",
            "6b934894de714c9a98aecead0dd55221",
            "3c33d78e85df4c68ba0ba948b3fb6162",
            "2061a628f2554a5f969281201fdcaa91",
            "05c4c3be28b649348d902c686317a343",
            "1648199d8a514c93abba9c0078d197b4",
            "c4e38b6042e1443ca856349e3f718ce2",
            "20d882aaff4b40d5ba58c6dda2414df7",
            "e6eac079d6af4d24b6cb356b39f00f94",
            "7627f7a56a9f44268363370b7f0f90f4",
            "5bdd27ba9f4040bda53575a12f89ec88",
            "476b0976110341219b9fa8b342f29306",
            "381113da71d541239814aa524f3ea5c9",
            "25b3b176c1bd4011a020572bd12cd026",
            "a02bcd56a0a64846a11b05ba166d3f7e",
            "f66675522c9747f3981ac5cbdf005390",
            "c14ca1d8bf9942b68cc964e81815fc61",
            "f10b0276bb774ca28386214334e36de2",
            "22db3236d7b640cbb6dc091956e92f2f",
            "46ac6a6031e846c8b8c83364a1f71db2",
            "431edfd6ddf140d991b7e35b44852dfb",
            "560ac26e408e44259e633fea2395882c",
            "9062601c7b9f447a8a632f779a90132f",
            "d321c975281e40aabc38d3ea2556c8e9"
          ]
        },
        "id": "ZTT_5IioKcAA",
        "outputId": "6ffb73f0-7aec-41f5-d73b-242316f7da60"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "08626170f0ca427cb2e55fe7de69aacc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c33d78e85df4c68ba0ba948b3fb6162",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "25b3b176c1bd4011a020572bd12cd026",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_ds = as_ds.map(tokenize_and_align_labels, batched=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYS4On3Uyvo3"
      },
      "source": [
        "### Training of the baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 720,
          "referenced_widgets": [
            "22d816fa62eb42af8e160ab5dcf37c04",
            "68f9980e508845f6bf99fb9131239a67",
            "722d90a6eb354150896a72879c9d309c",
            "8b74452345a74b1fa5ca79a57c1225c2",
            "6cc1244e73db4f2795fb68d31cfb23d7",
            "0341ebc3b9f545b4a2090b04e6c67458",
            "efc268d8b8024e9aaeeaaee093c2091d",
            "4963667863f84d0d8916d0e65b6cc0d6",
            "38787b0700cf480abeb76ef2d45e0c97",
            "dbe1021a26124341bab5b5400348af14",
            "ecea25c06b1346f9b1372af7ab41d888"
          ]
        },
        "id": "UWWG8o8eHibX",
        "outputId": "cdd95e5d-ad3f-4b18-9bb3-8be08f22e585"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "22d816fa62eb42af8e160ab5dcf37c04",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-2849737604.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjeynang05\u001b[0m (\u001b[33mjeynang05-nn\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251115_105507-pmvoyikf</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/jeynang05-nn/huggingface/runs/pmvoyikf' target=\"_blank\">ethereal-meadow-6</a></strong> to <a href='https://wandb.ai/jeynang05-nn/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/jeynang05-nn/huggingface' target=\"_blank\">https://wandb.ai/jeynang05-nn/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/jeynang05-nn/huggingface/runs/pmvoyikf' target=\"_blank\">https://wandb.ai/jeynang05-nn/huggingface/runs/pmvoyikf</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 23:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.843481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.701884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.631176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=39, training_loss=1.7418156159229767, metrics={'train_runtime': 1512.1862, 'train_samples_per_second': 0.198, 'train_steps_per_second': 0.026, 'total_flos': 19598142643200.0, 'train_loss': 1.7418156159229767, 'epoch': 3.0})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    num_labels=len(label_list)\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"baseline-as-ner\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XJ3i8KZI67e",
        "outputId": "e8741779-ca78-4b5b-9550-ec47a8ddadaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline XLM-R Assamese F1: 0.13733905579399142\n"
          ]
        }
      ],
      "source": [
        "preds_raw = preds.predictions.argmax(-1)\n",
        "labels_raw = preds.label_ids\n",
        "\n",
        "true_preds = [\n",
        "    [id2label[p] for p, l in zip(pred, lab) if l != -100]\n",
        "    for pred, lab in zip(preds_raw, labels_raw)\n",
        "]\n",
        "true_labels = [\n",
        "    [id2label[l] for p, l in zip(pred, lab) if l != -100]\n",
        "    for pred, lab in zip(preds_raw, labels_raw)\n",
        "]\n",
        "\n",
        "f1 = f1_score(true_labels, true_preds, average='micro')\n",
        "print(\"Baseline XLM-R Assamese F1:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Nwa8D4yy5e"
      },
      "source": [
        "As we can see we got f1 score of 0.13 which is extremely low"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajMtx3Of1HqG"
      },
      "source": [
        "# Training of the Proposed model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JrmixbbsAba"
      },
      "source": [
        "## How LoRA Works (Low-Rank Adaptation)\n",
        "\n",
        "LoRA freezes the main transformer weights and inserts small trainable matrices into specific layers (usually attention layers like Query and Value).\n",
        "\n",
        "Why LoRA helps:\n",
        "\n",
        "Instead of updating a full transformer layer (millions of parameters), LoRA introduces two tiny matrices:\n",
        "\n",
        "               A: down-projection (W → rank r)\n",
        "\n",
        "               B: up-projection (rank r → W)\n",
        "\n",
        "So instead of learning ΔW (huge), we learn:\n",
        "ΔW = B × A (very small)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401,
          "referenced_widgets": [
            "b46ef1792f894cc299b0c870b861c0c0",
            "0e0f0789b0d44738a3089d8c674a5909",
            "07116a00b2604f9bb64a8df72d8e7d38",
            "fa08f6f1eb0d411f9013dee03143b081",
            "90b2e5e8d324474fa68ea82abef208a5",
            "a41b67c5c4d34178a154a6651faef463",
            "d38fb62b7a3742d5aa949475ff9a3a1f",
            "57aa0c16e5bd4eaabec4e10187e2b4cc",
            "bfc1eb153ecb4697ab12226390bc9d57",
            "da1bcfbcefba42e28670af51603b5a3c",
            "f00dff64c4764683ac268ec1a1807aea",
            "6df0493b6e344db693b018b17bbd51c8",
            "f1669fe4fe034667a058ce2941828ab5",
            "beb256447b624db2a68ce0f4fc3a62b7",
            "4e6d381c7eda4cd28f44aa3fd039fcc9",
            "47b34c22d08d4aee8395eb074d0101d0",
            "a1e875f5dd864646b3194307ef9d649a",
            "a179c3cfd53f47b29509f4609d575a31",
            "2351ed4c9e14444ca0291cddd54da7e8",
            "9814a713e01c48afb0c53d0347716853",
            "8500f5c1068b4a91815441b7031d4373",
            "b2521dcdf8c6451d927a73e868feb09c",
            "e5b562ed648f49e38bcc204d87b1c82b",
            "5a7405d408bd44dcae83a0da6e67aba6",
            "589bfa917efb4302a9780dc765f1798d",
            "ef2a23a4db754790af930b61e481d907",
            "de94aa25017747959047fb1a90f300d3",
            "c9ef373a538b4e609688baaa1b4e3025",
            "b3eea59252e74bfa97f093acf9165996",
            "02d8186611be47f3bf129829caa7e337",
            "d67db13e7c794a749afda96072aa4ee4",
            "e3e985813491432b97d0952cfabd0dc5",
            "a923fe9d613c4d94b79ba32723bb2a18",
            "95da5a8b047b44738df54480ac209be1",
            "4e033537d6c346c4a4658ae7eb56b8c7",
            "363c773ca3ff4d2b81f7451b91a5f7e9",
            "2ae732a8a9f54b92bf2a0fbf1e5264b0",
            "1fbc39f1982440078cc9e5f6275f6fa8",
            "dd8cde9171e742a5b52b302b659c105d",
            "00dc0fc2eee848758c4f3bba95efcc37",
            "731b93b6f35d4f3e973a34b1e1dc7c6f",
            "0d20af6a9bae4c2d833febe14047eabc",
            "2b2a9ccef6cc465bb0ab508c4f086df2",
            "045a0182c897403fa83f087e06bd2cda",
            "c5fb0b9d6acf44598375822c4398a412",
            "5deb9fbee5994ecfb3a2aa9770a6ce21",
            "8164267a7c5c4d3fa18207a4c54b03dc",
            "17025d0c84b7477e80db2ae0c699d651",
            "f06909eb09844e26ba22344297b9edee",
            "c5e029cdeab84abf95a80034088aef3f",
            "3f9a956f5f3344498e2ed036bee32a1d",
            "6d6ce08791af4722845371bf568c2cf4",
            "5f8b71b6f6dc4e3aa18a6d1b6e830764",
            "4e22baf0d3a543d4a0b63c377d9d39fa",
            "7bd8ce2e052b424bb36f3c4959d2ae17",
            "71433d223c7f49d59159c53ee31c2e02",
            "d751879c26cd4d90abee1b595ffbbfcc",
            "2173e4df84d34c5cab988503aca88d32",
            "8c56ea391aeb4656a14cb18773af509f",
            "56647e2b788c48bdb2b23bba906afc13",
            "38511aa60532403890d1fcf1ea1bf303",
            "f4129eb48e1b4e14a8600f2841e467bf",
            "870f27b297334affadc5f68122147243",
            "ce4eac93be7044e6b72fb7958ba52afe",
            "e5695d7c59ac4c72bcdcb3e61399775c",
            "1d71396357274e2cae9f346e6af293a6",
            "38ca51f475ee40f5ba463f4a56e41a36",
            "e45c7bb2b3624c0db6e4a37ce992bda3",
            "04ba927bcc0d40ee9aab3ff71c0295ef",
            "e32b13eb3d844e57927df449042d4428",
            "08d232b32801484cbcd2c02754f61121",
            "239f792eee2146378d644b602b0f29d6",
            "330e6375fc4145dc8ac87ca3e66b1f22",
            "c6adca666cd74fa5ae04baea54cb61ac",
            "b170750a4b6345f99937a2fd200fac0f",
            "039c37c6555744c9afc542552b832a1e",
            "ae23320a86604f099bc2fa945a208d90",
            "cd917118b49c4e6793c1a285aab92f97",
            "71b226fecfd848c18ffb3c513d303ba5",
            "7d78cd390227430c95d61bfeee061bd3",
            "30c51f0887ad405b8cf06038855e5295",
            "09c1989945444c2bb7befc2c3f0f9c8b",
            "0b16706797964bbdbd47fab025c7aed7",
            "3333207ee7ef40eb8f7db59d52403303",
            "8d350bc5a0c04e27804cbca512a14874",
            "aae6f13260564972949822cdca0f8aed",
            "22347ec91fba46b18ad33a76210f4868",
            "ed962e907b7844bf993d10df70c29417",
            "7706aef65e304a338a987ac05d1ba9bf",
            "a2d831a93bb14723ae2d19d1b63707bc",
            "dac078f5681d47c1b9fba0cc0c0c3e1f",
            "7ec6193b82174353a40e4e6ea8b3198b",
            "90e4662fbae94b8bbd2874bb76fcf5fa",
            "dffed7eddb304350a144f57ca7b7b653",
            "9ff5ecd783a34016b128b1cfa9ca3b3e",
            "7b22d7deb62b4e588d163e9212047b07",
            "62b706a22f114293b4098d8c5fb27e90",
            "029f3c67459649078691b6df14a3b664",
            "203a3dcfc289493287e22d619d0f2547",
            "72f87ab449024e718585126de78c39f0",
            "b62c9627fbfa405e91442257759ac69c",
            "dd6776cb17264166865bf9ebf0624bd7",
            "69eab538ce65422893bd0ef2640b35ff",
            "5b916133ef174123a0c914c6c90c3fe2",
            "21729c9266af45538681739704399c38",
            "d9a1b52671bb47b6a6366cea5b8c057d",
            "446f5701c6a842e7a937f9ffb1dc89d8",
            "2f73bfc2718b45efb4daeead80ea94b7",
            "b73006e369904debbace0be9957c5d41",
            "f4d562b60df54200b929b73f32d1caa1",
            "ab410843b8764bc7a94eb374eac52e55",
            "8beb87a9d66342c3b58080e567f4c99a",
            "797018e9c4d74efbb6de6c532b6a2b22",
            "23120f7b08ab49c493d89735ff617d02",
            "5c8b79f9704f4bf69916e1979746dfa9",
            "bc7e0616cc6c442fa1256d20ca691173",
            "5b72026e912640c58bb16fd05fe4158a",
            "31cd54a071a841a5bdba11065f033298",
            "cd3a828f5f914e8aa826b9daf45a16a0",
            "481312a5e72547128ce06b16403199ae",
            "1e69d9c23da444d19f0491bf2b0bb96d",
            "8edd02c98acf4e32a95d54524abe12a0",
            "63c4d4f611bc477fa23f148c410634f0",
            "b5058050919743ac920edc61dfdb9d46",
            "3cab67407d0041dd9285bcf26cb8fe1f",
            "a445fee4253c40e0ba29938020764554",
            "4add9faa9ed142cc99c1964eac878515",
            "2596965e751649a9aa5bd782dfa52c83",
            "317dff4c9217480c88ddf236f8c5167d",
            "b13bcad298cb4c63bfa5ac1319b9efbb",
            "085e347941a84e5da6434bf58408fa53",
            "3c68c44a2baa41fcbe4943f37d75ccf7"
          ]
        },
        "id": "-bMsVu1RQoIH",
        "outputId": "864b9aa8-afe7-443f-c735-bcc4203e74bf"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b46ef1792f894cc299b0c870b861c0c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "hi/validation-00000-of-00001.parquet:   0%|          | 0.00/64.7k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6df0493b6e344db693b018b17bbd51c8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "hi/test-00000-of-00001.parquet:   0%|          | 0.00/65.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5b562ed648f49e38bcc204d87b1c82b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "hi/train-00000-of-00001.parquet:   0%|          | 0.00/312k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95da5a8b047b44738df54480ac209be1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5fb0b9d6acf44598375822c4398a412",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71433d223c7f49d59159c53ee31c2e02",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "38ca51f475ee40f5ba463f4a56e41a36",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bn/validation-00000-of-00001.parquet:   0%|          | 0.00/56.0k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cd917118b49c4e6793c1a285aab92f97",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bn/test-00000-of-00001.parquet:   0%|          | 0.00/57.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7706aef65e304a338a987ac05d1ba9bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "bn/train-00000-of-00001.parquet:   0%|          | 0.00/554k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "72f87ab449024e718585126de78c39f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab410843b8764bc7a94eb374eac52e55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8edd02c98acf4e32a95d54524abe12a0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hi_ds = load_dataset(\"wikiann\", \"hi\")\n",
        "bn_ds = load_dataset(\"wikiann\", \"bn\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2P6ATs1sTU4"
      },
      "source": [
        "### Stage 1 — Cross-Lingual Alignment (Hindi + Bengali)\n",
        "\n",
        "In this stage:\n",
        "\n",
        "- The base XLM-R model remains frozen\n",
        "\n",
        "- Only the LoRA adapter is trained\n",
        "\n",
        "- The model learns how Hindi and Bengali tokens should be represented for NER\n",
        "\n",
        "This step injects language-shared features into LoRA layers\n",
        "\n",
        "### Stage 2 — Assamese Fine-Tuning\n",
        "\n",
        "After the alignment step:\n",
        "\n",
        "- We load a clean XLM-R base model\n",
        "\n",
        "- Attach the trained LoRA adapter using PeftModel.from_pretrained\n",
        "\n",
        "- Fine-tune on Assamese NER for 2–6 epochs\n",
        "\n",
        "This stage adapts the aligned multilingual LoRA weights to Assamese-specific entity patterns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "741ce64c330340adb8b7dfe1c60aa431",
            "87baab10cf364e6880981a225cfcdef7",
            "88d828674dc34aa7b550ed2997d3d73e",
            "788ac6e84bea4e9485b7484d5a50eed4",
            "7974e463b94b4344aa1b9146bec5b02a",
            "a93ce3aedce247ea9883f76664cb0178",
            "4a5d6ed079f945d3a3bc4ad93dcea488",
            "43d9091a797e4b65ba9f94ae654a0f69",
            "0128cbec107e4a1ea658cc6c61a484b6",
            "efe8f9f86d26459a866ac074c6f00570",
            "aff429fc9bae496da3e400f4e22fd421",
            "e5417a2e4a014c688eb6c90f4708b5d4",
            "159345cd2cd744f9880adee87b5df5ea",
            "d7f11aa416b249b794b02f9aaf8eb1ae",
            "6f5f777e58bf49bdb69324b52d121a0c",
            "6aa96899d7e04194a9902c38ee124813",
            "9fc84f412e3a49d6a53f9e300b275c32",
            "113edd0e22e74c22a19bf499f6d8c342",
            "a1169dda6d87462ca8cd3a466f637066",
            "51c7c0537da4494ab40c855820a5d092",
            "8efc5c32193449bba03aa582e8e5c997",
            "bc677658d8474e0db3a806a386c844e7",
            "fbdbf0cdfeab4fb7a6a801f71fcfbc08",
            "e465ec6db0884edaa644338b69bbb402",
            "f417312535574e86a88d4a283d4e1492",
            "f67093314aa649db9be0b79af0203b06",
            "79a630a43636421fa649582199b1e996",
            "7c5f6a89aa264471a474362656a157f1",
            "e7647737f437472fa478e4a6fe368da2",
            "c6aeb91f7a484275bd02af7cc46399e6",
            "9ad0a8f8e8a74e6a82ab35a857737276",
            "c5987c523f734636b446101ba648537b",
            "cb9602fbe0c945569122192c716d442b",
            "bb24454eee2a4a478cf490cff98efb51",
            "daf8efa9a82845d087c9291a26846ad0",
            "b499e7318e874c52ad74a826791c8d76",
            "bb06f120d84c4e2e83e6e82df3c1c099",
            "4b88a419ff7442e28ce8278dcf9db4dd",
            "aca993a1cd374b8fb6ca9e44ae4ff899",
            "5f58014f7e31492a91f5c4f4fd80aa19",
            "bcdc80e1844d4d5e8f1314c1b0080aa3",
            "098fa78ac8914701905886d9acd360cc",
            "1b5aa679dbd54d44a965c0de7d66f015",
            "9341d63137754be190e77c4627918f52",
            "8d57ef31232c45bfafc44e16ce30ea40",
            "449fe3d903b84cfd96a4b26638ca7b6c",
            "974861d7edaf4fc196a1c2f726ad0508",
            "6455be44bd614c0391c91365c842ab27",
            "b3cc3320cfa5499bb80284c430b94c6c",
            "af3c99e7b68b480e84e8ae5cfefd06c5",
            "2b44afc6cf45464587d76eb8a3087ebd",
            "0bc7a08308d7446ab0a1ea09431feefe",
            "1a8a2d09c0e9416bafc1d66fe91e121b",
            "258da7c567864fdbbde039dced289feb",
            "773fa5df5e76478eb03de70925c6adfa",
            "eeef7e0346a24c3aa3a13af56e225259",
            "9c360a58a47f4ef8972079368cfa1926",
            "92900b08de8640449ac18f16150dc0f6",
            "47df257b61b342108b253a564ee6524c",
            "6df656f2a2d84b578f59f86beb63618f",
            "33fa2036983249a6b6a63440d4bf638e",
            "febe5c16fe094ecd9c6be247385b6527",
            "748cb35677984680b04f5c299a491ba1",
            "a21b5092feee4827af81701bde941857",
            "8933656627b347b9bb27972151d69ab7",
            "ce0d2f8a06334201a92f78486b8ab45e"
          ]
        },
        "id": "P5Sr31B_QzTA",
        "outputId": "2a2703e0-4fc4-48db-c79c-08beb5215d17"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "741ce64c330340adb8b7dfe1c60aa431",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5417a2e4a014c688eb6c90f4708b5d4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fbdbf0cdfeab4fb7a6a801f71fcfbc08",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb24454eee2a4a478cf490cff98efb51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d57ef31232c45bfafc44e16ce30ea40",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eeef7e0346a24c3aa3a13af56e225259",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def align_labels(ds):\n",
        "    return ds.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "hi_tok = align_labels(hi_ds)\n",
        "bn_tok = align_labels(bn_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "9_IEDWS_RC5u"
      },
      "outputs": [],
      "source": [
        "multilingual_train = DatasetDict({\n",
        "    \"train\": concatenate_datasets([\n",
        "        hi_tok[\"train\"].shuffle(seed=42).select(range(5000)),\n",
        "        bn_tok[\"train\"].shuffle(seed=42).select(range(5000))\n",
        "    ]),\n",
        "    \"validation\": concatenate_datasets([\n",
        "        hi_tok[\"validation\"],\n",
        "        bn_tok[\"validation\"]\n",
        "    ])\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3n_oBIsSjf9",
        "outputId": "27bb2faa-6b99-4041-e5c3-ed96fe4d021a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 318,727 || all params: 277,758,734 || trainable%: 0.1147\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:73: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:196: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.05,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    bias=\"lora_only\",\n",
        "    task_type=\"TOKEN_CLS\"\n",
        ")\n",
        "\n",
        "peft_model = get_peft_model(model, lora_config)\n",
        "peft_model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "u0dYS-_0SsVV",
        "outputId": "d925f542-5ea3-4fbb-bbb9-a5d3828236d8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3320096437.py:12: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  xl_trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7500/7500 08:41, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.571200</td>\n",
              "      <td>0.439305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.467000</td>\n",
              "      <td>0.384081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.390900</td>\n",
              "      <td>0.342306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.386900</td>\n",
              "      <td>0.320200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.349600</td>\n",
              "      <td>0.304806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.354500</td>\n",
              "      <td>0.303788</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7500, training_loss=0.4657651870727539, metrics={'train_runtime': 521.5023, 'train_samples_per_second': 115.052, 'train_steps_per_second': 14.382, 'total_flos': 3933466122240000.0, 'train_loss': 0.4657651870727539, 'epoch': 6.0})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xl_training_args = TrainingArguments(\n",
        "    output_dir=\"cross-lingual-hi-bn\",\n",
        "    learning_rate=8e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    num_train_epochs=6,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_steps=100,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "xl_trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=xl_training_args,\n",
        "    train_dataset=multilingual_train[\"train\"],\n",
        "    eval_dataset=multilingual_train[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "xl_trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "df-OlugWSyXy"
      },
      "outputs": [],
      "source": [
        "peft_model.save_pretrained(\"hi_bn_lora_adapter\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdEwnblVlK_T",
        "outputId": "dbec5de1-5911-4ee9-ef22-8fa9614a3e60"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification\n",
        "from peft import PeftModel\n",
        "\n",
        "final_model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    num_labels=len(label_list)\n",
        ")\n",
        "\n",
        "final_model = PeftModel.from_pretrained(\n",
        "    final_model,\n",
        "    \"hi_bn_lora_adapter\"\n",
        ")\n",
        "\n",
        "final_model.set_adapter(\"default\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DWqh_YP1ZX8"
      },
      "outputs": [],
      "source": [
        "# If we use bias=\"none\" in LoRa config then run this code\n",
        "'''final_model = AutoModelForTokenClassification.from_pretrained(\n",
        "    \"xlm-roberta-base\",\n",
        "    num_labels=len(label_list)\n",
        ")\n",
        "\n",
        "final_model = get_peft_model(final_model, lora_config)\n",
        "final_model.load_adapter(\"hi_bn_lora_adapter\" ,adapter_name=\"none\")#adapter_name=\"hi_bn_xfer\")\n",
        "final_model.set_adapter(\"hi_bn_xfer\")'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "e5cMU9InS4iB",
        "outputId": "4789efb0-a940-43f9-c600-de0bec03a06f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-4050113234.py:10: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  final_trainer = Trainer(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='39' max='39' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [39/39 00:03, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.661119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.568001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>0.570006</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=39, training_loss=0.5809201949681991, metrics={'train_runtime': 3.1869, 'train_samples_per_second': 94.134, 'train_steps_per_second': 12.237, 'total_flos': 19667330611200.0, 'train_loss': 0.5809201949681991, 'epoch': 3.0})"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_args = TrainingArguments(\n",
        "    output_dir=\"assamese-final-model\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=3,\n",
        "    eval_strategy=\"epoch\",\n",
        ")\n",
        "\n",
        "final_trainer = Trainer(\n",
        "    model=final_model,\n",
        "    args=final_args,\n",
        "    train_dataset=tokenized_ds[\"train\"],\n",
        "    eval_dataset=tokenized_ds[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "final_trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nroJ4QykTARo",
        "outputId": "42aa9c67-8be5-438f-8f84-ca13a342b2b9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Cross-Lingual Assamese F1: 0.7210300429184548\n"
          ]
        }
      ],
      "source": [
        "preds = final_trainer.predict(tokenized_ds[\"test\"])\n",
        "\n",
        "preds_raw = preds.predictions.argmax(-1)\n",
        "labels_raw = preds.label_ids\n",
        "\n",
        "true_preds = [\n",
        "    [id2label[p] for p, l in zip(pred, lab) if l != -100]\n",
        "    for pred, lab in zip(preds_raw, labels_raw)\n",
        "]\n",
        "true_labels = [\n",
        "    [id2label[l] for p, l in zip(pred, lab) if l != -100]\n",
        "    for pred, lab in zip(preds_raw, labels_raw)\n",
        "]\n",
        "\n",
        "f1 = f1_score(true_labels, true_preds, average=\"micro\")\n",
        "print(\"Final Cross-Lingual Assamese F1:\", f1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl944Swy1s6a"
      },
      "source": [
        "## Conclusion\n",
        "- Baseline F1: ~0.13\n",
        "\n",
        "- After LoRA + Cross-Lingual Training: ~0.72\n",
        "\n",
        "XLM-R alone is not enough for Assamese NER due to low-resource constraints.\n",
        "Cross-lingual signal + LoRA dramatically improves results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os7U_Ao6Pew7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
